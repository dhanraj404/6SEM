dhanrz@G7-7588:/opt$ cd hadoop
dhanrz@G7-7588:/opt/hadoop$ sbin/start-all.sh
WARNING: Attempting to start all Apache Hadoop daemons as dhanrz in 10 seconds.
WARNING: This is not a recommended production deployment configuration.
WARNING: Use CTRL-C to abort.
Starting namenodes on [localhost]
Starting datanodes
Starting secondary namenodes [G7-7588]
Starting resourcemanager
Starting nodemanagers
dhanrz@G7-7588:/opt/hadoop$ jps
4128 NameNode
5251 Jps
4264 DataNode
4745 ResourceManager
4878 NodeManager
4463 SecondaryNameNode
dhanrz@G7-7588:/opt/hadoop$ hdfs dfs -ls /
Found 3 items
drwxr-xr-x   - dhanrz supergroup          0 2021-05-08 08:06 /input_dir
drwxr-xr-x   - dhanrz supergroup          0 2021-05-08 07:57 /test
drwx------   - dhanrz supergroup          0 2021-05-08 08:13 /tmp
dhanrz@G7-7588:/opt/hadoop$ hdfs dfs -rm -r /input_dir
Deleted /input_dir
dhanrz@G7-7588:/opt/hadoop$ hdfs dfs -ls /
Found 2 items
drwxr-xr-x   - dhanrz supergroup          0 2021-05-08 07:57 /test
drwx------   - dhanrz supergroup          0 2021-05-08 08:13 /tmp
dhanrz@G7-7588:/opt/hadoop$ hdfs dfs -mkdir /input_dir
dhanrz@G7-7588:/opt/hadoop$ hdfs dfs -ls /
Found 3 items
drwxr-xr-x   - dhanrz supergroup          0 2021-05-21 09:30 /input_dir
drwxr-xr-x   - dhanrz supergroup          0 2021-05-08 07:57 /test
drwx------   - dhanrz supergroup          0 2021-05-08 08:13 /tmp
dhanrz@G7-7588:/opt/hadoop$ hadoop fs -put /home/dhanrz/WEEK6/input.txt /input_dir
dhanrz@G7-7588:/opt/hadoop$ hdfs dfs -cat /input_dir/input.txt
HELLO
WORLD
HELLO
HADOOP
BYE
DHANRAJ_K

dhanrz@G7-7588:/opt/hadoop$ hadoop jar /home/dhanrz/WEEK6/sort.jar samples.topn.topN /input_dir/input.txt /output_dir
Exception in thread "main" java.lang.ClassNotFoundException: samples.topn.topN
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:348)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:316)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:236)
dhanrz@G7-7588:/opt/hadoop$ hadoop jar /home/dhanrz/WEEK6/sort.jar samples.topn.TopN /input_dir/input.txt /output_dir
2021-05-21 09:38:28,399 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
2021-05-21 09:38:28,748 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/dhanrz/.staging/job_1621569488057_0001
2021-05-21 09:38:29,015 INFO input.FileInputFormat: Total input files to process : 1
2021-05-21 09:38:29,348 INFO mapreduce.JobSubmitter: number of splits:1
2021-05-21 09:38:30,274 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1621569488057_0001
2021-05-21 09:38:30,277 INFO mapreduce.JobSubmitter: Executing with tokens: []
2021-05-21 09:38:30,443 INFO conf.Configuration: resource-types.xml not found
2021-05-21 09:38:30,443 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2021-05-21 09:38:30,601 INFO impl.YarnClientImpl: Submitted application application_1621569488057_0001
2021-05-21 09:38:30,624 INFO mapreduce.Job: The url to track the job: http://G7-7588:8088/proxy/application_1621569488057_0001/
2021-05-21 09:38:30,625 INFO mapreduce.Job: Running job: job_1621569488057_0001
2021-05-21 09:38:36,732 INFO mapreduce.Job: Job job_1621569488057_0001 running in uber mode : false
2021-05-21 09:38:36,734 INFO mapreduce.Job:  map 0% reduce 0%
2021-05-21 09:38:39,800 INFO mapreduce.Job:  map 100% reduce 0%
2021-05-21 09:38:44,835 INFO mapreduce.Job:  map 100% reduce 100%
2021-05-21 09:38:45,855 INFO mapreduce.Job: Job job_1621569488057_0001 completed successfully
2021-05-21 09:38:45,918 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=87
		FILE: Number of bytes written=469747
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=153
		HDFS: Number of bytes written=45
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
		HDFS: Number of bytes read erasure-coded=0
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=1308
		Total time spent by all reduces in occupied slots (ms)=1681
		Total time spent by all map tasks (ms)=1308
		Total time spent by all reduce tasks (ms)=1681
		Total vcore-milliseconds taken by all map tasks=1308
		Total vcore-milliseconds taken by all reduce tasks=1681
		Total megabyte-milliseconds taken by all map tasks=1339392
		Total megabyte-milliseconds taken by all reduce tasks=1721344
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=67
		Map output materialized bytes=87
		Input split bytes=106
		Combine input records=0
		Combine output records=0
		Reduce input groups=6
		Reduce shuffle bytes=87
		Reduce input records=7
		Reduce output records=6
		Spilled Records=14
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=51
		CPU time spent (ms)=760
		Physical memory (bytes) snapshot=496914432
		Virtual memory (bytes) snapshot=5229215744
		Total committed heap usage (bytes)=515375104
		Peak Map Physical memory (bytes)=299651072
		Peak Map Virtual memory (bytes)=2610003968
		Peak Reduce Physical memory (bytes)=197263360
		Peak Reduce Virtual memory (bytes)=2619211776
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=47
	File Output Format Counters 
		Bytes Written=45
dhanrz@G7-7588:/opt/hadoop$ hdfs dfs -cat /output_dir/*
hello	2
hadoop	1
world	1
k	1
dhanraj	1
bye	1
dhanrz@G7-7588:/opt/hadoop$ 


